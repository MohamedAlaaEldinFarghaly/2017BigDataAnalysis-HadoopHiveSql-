LoadingData 2015
Logging initialized using configuration in file:/etc/hive/conf.dist/hive-log4j.properties
OK
Time taken: 0.506 seconds
OK
Time taken: 2.377 seconds
Loading data to table default.tempor
chgrp: changing ownership of 'hdfs://quickstart.cloudera:8020/user/hive/warehouse/tempor/complete2015.csv': User does not belong to supergroup
Table default.tempor stats: [numFiles=1, numRows=0, totalSize=2864071408, rawDataSize=0]
OK
Time taken: 2.424 seconds
OK
Time taken: 0.548 seconds
Query ID = cloudera_20171216141515_cce82c72-cd02-4682-8eae-2a8adafe686e
Total jobs = 3
Launching Job 1 out of 3
Number of reduce tasks is set to 0 since there's no reduce operator
Starting Job = job_1513212655323_0062, Tracking URL = http://quickstart.cloudera:8088/proxy/application_1513212655323_0062/
Kill Command = /usr/lib/hadoop/bin/hadoop job  -kill job_1513212655323_0062
Hadoop job information for Stage-1: number of mappers: 11; number of reducers: 0
2017-12-16 14:16:22,136 Stage-1 map = 0%,  reduce = 0%
2017-12-16 14:38:14,142 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 207.85 sec
MapReduce Total cumulative CPU time: 3 minutes 27 seconds 850 msec
Ended Job = job_1513212655323_0062
Stage-4 is selected by condition resolver.
Stage-3 is filtered out by condition resolver.
Stage-5 is filtered out by condition resolver.
Moving data to: hdfs://quickstart.cloudera:8020/user/hive/warehouse/project/.hive-staging_hive_2017-12-16_14-15-37_844_3647593894845782845-1/-ext-10000
Loading data to table default.project
[Warning] could not update stats.
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 11   Cumulative CPU: 207.85 sec   HDFS Read: 2864275927 HDFS Write: 2864055116 SUCCESS
Total MapReduce CPU Time Spent: 3 minutes 27 seconds 850 msec
OK
Time taken: 1420.019 seconds
-------------------------------------------------------------------------------------------------------------------------------------------------------------------
ProjectQ2A1 "outputQuestion2Answer1Precinct"
Logging initialized using configuration in file:/etc/hive/conf.dist/hive-log4j.properties
OK
Time taken: 0.725 seconds
OK
Time taken: 2.093 seconds
Query ID = cloudera_20171216160505_942a55af-79e8-46be-8f49-172113662ccd
Total jobs = 1
Launching Job 1 out of 1
Number of reduce tasks not specified. Estimated from input data size: 20
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513212655323_0064, Tracking URL = http://quickstart.cloudera:8088/proxy/application_1513212655323_0064/
Kill Command = /usr/lib/hadoop/bin/hadoop job  -kill job_1513212655323_0064
Hadoop job information for Stage-1: number of mappers: 19; number of reducers: 20
2017-12-16 16:06:10,098 Stage-1 map = 0%,  reduce = 0%
2017-12-16 16:43:36,275 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 219.24 sec
MapReduce Total cumulative CPU time: 3 minutes 39 seconds 240 msec
Ended Job = job_1513212655323_0064
Loading data to table default.countingsimilars
Table default.countingsimilars stats: [numFiles=20, numRows=628, totalSize=4203, rawDataSize=3575]
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 19  Reduce: 20   Cumulative CPU: 219.24 sec   HDFS Read: 5016300287 HDFS Write: 5823 SUCCESS
Total MapReduce CPU Time Spent: 3 minutes 39 seconds 240 msec
OK
Time taken: 2365.481 seconds
Query ID = cloudera_20171216164545_d2922268-504a-477f-89f4-fcc7dc1e2750
Total jobs = 2
Launching Job 1 out of 2
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513212655323_0065, Tracking URL = http://quickstart.cloudera:8088/proxy/application_1513212655323_0065/
Kill Command = /usr/lib/hadoop/bin/hadoop job  -kill job_1513212655323_0065
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2017-12-16 16:45:37,207 Stage-1 map = 0%,  reduce = 0%
2017-12-16 16:45:51,066 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 1.61 sec
2017-12-16 16:46:01,547 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 3.5 sec
MapReduce Total cumulative CPU time: 3 seconds 500 msec
Ended Job = job_1513212655323_0065
Launching Job 2 out of 2
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513212655323_0066, Tracking URL = http://quickstart.cloudera:8088/proxy/application_1513212655323_0066/
Kill Command = /usr/lib/hadoop/bin/hadoop job  -kill job_1513212655323_0066
Hadoop job information for Stage-2: number of mappers: 1; number of reducers: 1
2017-12-16 16:46:19,480 Stage-2 map = 0%,  reduce = 0%
2017-12-16 16:46:28,126 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 1.17 sec
2017-12-16 16:46:39,275 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 3.16 sec
MapReduce Total cumulative CPU time: 3 seconds 160 msec
Ended Job = job_1513212655323_0066
Copying data to local directory outputQuestion2Answer1Precinct
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 3.5 sec   HDFS Read: 11431 HDFS Write: 579 SUCCESS
Stage-Stage-2: Map: 1  Reduce: 1   Cumulative CPU: 3.16 sec   HDFS Read: 5255 HDFS Write: 205 SUCCESS
Total MapReduce CPU Time Spent: 6 seconds 660 msec
OK
Time taken: 98.569 seconds
-------------------------------------------------------------------------------------------------------------------------------------------------------------------
ProjectQ1A1 "outputQuestion1Answer1hour"
Logging initialized using configuration in file:/etc/hive/conf.dist/hive-log4j.properties
OK
Time taken: 2.234 seconds
OK
Time taken: 0.995 seconds
Query ID = cloudera_20171218111515_c07414ed-69d0-4fba-8019-daf1e3d21d40
Total jobs = 3
Launching Job 1 out of 3
Number of reduce tasks is set to 0 since there's no reduce operator
Starting Job = job_1513559662109_0012, Tracking URL = http://quickstart.cloudera:8088/proxy/application_1513559662109_0012/
Kill Command = /usr/lib/hadoop/bin/hadoop job  -kill job_1513559662109_0012
Hadoop job information for Stage-1: number of mappers: 19; number of reducers: 0
2017-12-18 11:15:19,511 Stage-1 map = 0%,  reduce = 0%
2017-12-18 11:28:10,096 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 204.46 sec
MapReduce Total cumulative CPU time: 3 minutes 24 seconds 460 msec
Ended Job = job_1513559662109_0012
Stage-4 is filtered out by condition resolver.
Stage-3 is selected by condition resolver.
Stage-5 is filtered out by condition resolver.
Launching Job 3 out of 3
Number of reduce tasks is set to 0 since there's no reduce operator
Starting Job = job_1513559662109_0013, Tracking URL = http://quickstart.cloudera:8088/proxy/application_1513559662109_0013/
Kill Command = /usr/lib/hadoop/bin/hadoop job  -kill job_1513559662109_0013
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 0
2017-12-18 11:29:15,981 Stage-3 map = 0%,  reduce = 0%
2017-12-18 11:29:39,698 Stage-3 map = 33%,  reduce = 0%, Cumulative CPU 8.72 sec
2017-12-18 11:29:46,026 Stage-3 map = 67%,  reduce = 0%, Cumulative CPU 13.16 sec
2017-12-18 11:29:52,405 Stage-3 map = 92%,  reduce = 0%, Cumulative CPU 17.15 sec
2017-12-18 11:29:53,449 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 17.89 sec
MapReduce Total cumulative CPU time: 17 seconds 890 msec
Ended Job = job_1513559662109_0013
Loading data to table default.countingsimilars
Table default.countingsimilars stats: [numFiles=1, numRows=22429627, totalSize=112148099, rawDataSize=89718472]
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 19   Cumulative CPU: 204.46 sec   HDFS Read: 5016208867 HDFS Write: 112149808 SUCCESS
Stage-Stage-3: Map: 1   Cumulative CPU: 17.89 sec   HDFS Read: 112153272 HDFS Write: 112148099 SUCCESS
Total MapReduce CPU Time Spent: 3 minutes 42 seconds 350 msec
OK
Time taken: 911.908 seconds
Query ID = cloudera_20171218113030_9cb535d3-1c73-40ea-a211-95fbf751b567
Total jobs = 3
Launching Job 1 out of 3
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513559662109_0014, Tracking URL = http://quickstart.cloudera:8088/proxy/application_1513559662109_0014/
Kill Command = /usr/lib/hadoop/bin/hadoop job  -kill job_1513559662109_0014
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2017-12-18 11:30:38,276 Stage-1 map = 0%,  reduce = 0%
2017-12-18 11:30:59,271 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 15.19 sec
2017-12-18 11:31:09,050 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 17.2 sec
MapReduce Total cumulative CPU time: 17 seconds 200 msec
Ended Job = job_1513559662109_0014
Launching Job 2 out of 3
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513559662109_0015, Tracking URL = http://quickstart.cloudera:8088/proxy/application_1513559662109_0015/
Kill Command = /usr/lib/hadoop/bin/hadoop job  -kill job_1513559662109_0015
Hadoop job information for Stage-2: number of mappers: 1; number of reducers: 1
2017-12-18 11:31:23,880 Stage-2 map = 0%,  reduce = 0%
2017-12-18 11:31:30,318 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 1.09 sec
2017-12-18 11:31:39,046 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 3.15 sec
MapReduce Total cumulative CPU time: 3 seconds 150 msec
Ended Job = job_1513559662109_0015
Launching Job 3 out of 3
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513559662109_0016, Tracking URL = http://quickstart.cloudera:8088/proxy/application_1513559662109_0016/
Kill Command = /usr/lib/hadoop/bin/hadoop job  -kill job_1513559662109_0016
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2017-12-18 11:32:04,894 Stage-3 map = 0%,  reduce = 0%
2017-12-18 11:32:11,437 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.0 sec
2017-12-18 11:32:27,474 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 2.86 sec
MapReduce Total cumulative CPU time: 2 seconds 860 msec
Ended Job = job_1513559662109_0016
Copying data to local directory outputQuestion1Answer1hour
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 17.2 sec   HDFS Read: 112154683 HDFS Write: 1335 SUCCESS
Stage-Stage-2: Map: 1  Reduce: 1   Cumulative CPU: 3.15 sec   HDFS Read: 5803 HDFS Write: 720 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 2.86 sec   HDFS Read: 5625 HDFS Write: 297 SUCCESS
Total MapReduce CPU Time Spent: 23 seconds 210 msec
OK
Time taken: 134.035 seconds
-------------------------------------------------------------------------------------------------------------------------------------------------------------------
ProjectQ1A2 "outputQuestion1Answer2Month"
Logging initialized using configuration in file:/etc/hive/conf.dist/hive-log4j.properties
OK
Time taken: 20.67 seconds
OK
Time taken: 1.522 seconds
Query ID = cloudera_20171218102828_fb20e00a-9184-45e4-943c-085c5e05b18c
Total jobs = 3
Launching Job 1 out of 3
Number of reduce tasks is set to 0 since there's no reduce operator
Starting Job = job_1513559662109_0002, Tracking URL = http://quickstart.cloudera:8088/proxy/application_1513559662109_0002/
Kill Command = /usr/lib/hadoop/bin/hadoop job  -kill job_1513559662109_0002
Hadoop job information for Stage-1: number of mappers: 19; number of reducers: 0
2017-12-18 10:28:39,651 Stage-1 map = 0%,  reduce = 0%
2017-12-18 10:29:40,670 Stage-1 map = 0%,  reduce = 0%
2017-12-18 10:30:40,947 Stage-1 map = 13%,  reduce = 0%, Cumulative CPU 35.87 sec
2017-12-18 10:31:11,384 Stage-1 map = 16%,  reduce = 0%, Cumulative CPU 49.67 sec
2017-12-18 10:31:12,435 Stage-1 map = 21%,  reduce = 0%, Cumulative CPU 50.74 sec
2017-12-18 10:31:13,473 Stage-1 map = 26%,  reduce = 0%, Cumulative CPU 51.0 sec
2017-12-18 10:31:17,630 Stage-1 map = 29%,  reduce = 0%, Cumulative CPU 52.39 sec
2017-12-18 10:31:29,088 Stage-1 map = 32%,  reduce = 0%, Cumulative CPU 54.41 sec
2017-12-18 10:32:29,265 Stage-1 map = 32%,  reduce = 0%, Cumulative CPU 83.66 sec
2017-12-18 10:33:14,242 Stage-1 map = 34%,  reduce = 0%, Cumulative CPU 95.85 sec
2017-12-18 10:33:15,390 Stage-1 map = 37%,  reduce = 0%, Cumulative CPU 96.18 sec
2017-12-18 10:33:16,590 Stage-1 map = 39%,  reduce = 0%, Cumulative CPU 96.42 sec
2017-12-18 10:33:18,994 Stage-1 map = 45%,  reduce = 0%, Cumulative CPU 99.5 sec
2017-12-18 10:33:21,263 Stage-1 map = 47%,  reduce = 0%, Cumulative CPU 100.06 sec
2017-12-18 10:34:21,981 Stage-1 map = 47%,  reduce = 0%, Cumulative CPU 113.28 sec
2017-12-18 10:34:23,172 Stage-1 map = 53%,  reduce = 0%, Cumulative CPU 113.42 sec
2017-12-18 10:34:26,310 Stage-1 map = 55%,  reduce = 0%, Cumulative CPU 113.73 sec
2017-12-18 10:34:28,403 Stage-1 map = 61%,  reduce = 0%, Cumulative CPU 114.27 sec
2017-12-18 10:34:31,564 Stage-1 map = 63%,  reduce = 0%, Cumulative CPU 115.08 sec
2017-12-18 10:35:32,172 Stage-1 map = 63%,  reduce = 0%, Cumulative CPU 141.16 sec
2017-12-18 10:36:07,475 Stage-1 map = 74%,  reduce = 0%, Cumulative CPU 156.16 sec
2017-12-18 10:36:13,708 Stage-1 map = 79%,  reduce = 0%, Cumulative CPU 158.26 sec
2017-12-18 10:36:59,356 Stage-1 map = 82%,  reduce = 0%, Cumulative CPU 167.82 sec
2017-12-18 10:37:01,434 Stage-1 map = 84%,  reduce = 0%, Cumulative CPU 168.09 sec
2017-12-18 10:37:06,449 Stage-1 map = 87%,  reduce = 0%, Cumulative CPU 169.56 sec
2017-12-18 10:37:08,394 Stage-1 map = 95%,  reduce = 0%, Cumulative CPU 170.69 sec
2017-12-18 10:37:25,348 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 176.88 sec
MapReduce Total cumulative CPU time: 2 minutes 56 seconds 880 msec
Ended Job = job_1513559662109_0002
Stage-4 is filtered out by condition resolver.
Stage-3 is selected by condition resolver.
Stage-5 is filtered out by condition resolver.
Launching Job 3 out of 3
Number of reduce tasks is set to 0 since there's no reduce operator
Starting Job = job_1513559662109_0003, Tracking URL = http://quickstart.cloudera:8088/proxy/application_1513559662109_0003/
Kill Command = /usr/lib/hadoop/bin/hadoop job  -kill job_1513559662109_0003
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 0
2017-12-18 10:37:46,215 Stage-3 map = 0%,  reduce = 0%
2017-12-18 10:38:03,965 Stage-3 map = 56%,  reduce = 0%, Cumulative CPU 9.89 sec
2017-12-18 10:38:10,183 Stage-3 map = 92%,  reduce = 0%, Cumulative CPU 15.0 sec
2017-12-18 10:38:11,221 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 15.57 sec
MapReduce Total cumulative CPU time: 15 seconds 570 msec
Ended Job = job_1513559662109_0003
Loading data to table default.countingsimilars
Table default.countingsimilars stats: [numFiles=1, numRows=22436000, totalSize=67308000, rawDataSize=44872000]
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 19   Cumulative CPU: 176.88 sec   HDFS Read: 5016206169 HDFS Write: 67309709 SUCCESS
Stage-Stage-3: Map: 1   Cumulative CPU: 15.57 sec   HDFS Read: 67313098 HDFS Write: 67308000 SUCCESS
Total MapReduce CPU Time Spent: 3 minutes 12 seconds 450 msec
OK
Time taken: 625.802 seconds
Query ID = cloudera_20171218103838_91586dc3-7fe7-49c3-b60c-8bc45441e3b3
Total jobs = 3
Launching Job 1 out of 3
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513559662109_0004, Tracking URL = http://quickstart.cloudera:8088/proxy/application_1513559662109_0004/
Kill Command = /usr/lib/hadoop/bin/hadoop job  -kill job_1513559662109_0004
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2017-12-18 10:39:00,105 Stage-1 map = 0%,  reduce = 0%
2017-12-18 10:39:19,083 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 12.37 sec
2017-12-18 10:39:36,843 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 13.87 sec
MapReduce Total cumulative CPU time: 13 seconds 870 msec
Ended Job = job_1513559662109_0004
Launching Job 2 out of 3
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513559662109_0005, Tracking URL = http://quickstart.cloudera:8088/proxy/application_1513559662109_0005/
Kill Command = /usr/lib/hadoop/bin/hadoop job  -kill job_1513559662109_0005
Hadoop job information for Stage-2: number of mappers: 1; number of reducers: 1
2017-12-18 10:39:51,515 Stage-2 map = 0%,  reduce = 0%
2017-12-18 10:39:57,775 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 0.95 sec
2017-12-18 10:40:05,146 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 2.32 sec
MapReduce Total cumulative CPU time: 2 seconds 320 msec
Ended Job = job_1513559662109_0005
Launching Job 3 out of 3
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513559662109_0006, Tracking URL = http://quickstart.cloudera:8088/proxy/application_1513559662109_0006/
Kill Command = /usr/lib/hadoop/bin/hadoop job  -kill job_1513559662109_0006
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2017-12-18 10:40:14,404 Stage-3 map = 0%,  reduce = 0%
2017-12-18 10:40:20,688 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 0.95 sec
2017-12-18 10:40:28,996 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 2.56 sec
MapReduce Total cumulative CPU time: 2 seconds 560 msec
Ended Job = job_1513559662109_0006
Copying data to local directory outputQuestion1Answer2Month
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 13.87 sec   HDFS Read: 67314164 HDFS Write: 384 SUCCESS
Stage-Stage-2: Map: 1  Reduce: 1   Cumulative CPU: 2.32 sec   HDFS Read: 4536 HDFS Write: 384 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 2.56 sec   HDFS Read: 5020 HDFS Write: 132 SUCCESS
Total MapReduce CPU Time Spent: 18 seconds 750 msec
OK
Time taken: 102.256 seconds
-------------------------------------------------------------------------------------------------------------------------------------------------------------------
ProjectQ2A2 "outputQuestion2Answer2Street"
Logging initialized using configuration in file:/etc/hive/conf.dist/hive-log4j.properties
OK
Time taken: 5.181 seconds
OK
Time taken: 3.276 seconds
Query ID = cloudera_20171216195959_b411e12b-36d3-4cb3-a05a-b5ce03d197ee
Total jobs = 1
Launching Job 1 out of 1
Number of reduce tasks not specified. Estimated from input data size: 20
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513212655323_0075, Tracking URL = http://quickstart.cloudera:8088/proxy/application_1513212655323_0075/
Kill Command = /usr/lib/hadoop/bin/hadoop job  -kill job_1513212655323_0075
Hadoop job information for Stage-1: number of mappers: 19; number of reducers: 20
2017-12-16 19:59:33,918 Stage-1 map = 0%,  reduce = 0%
2017-12-16 20:34:53,795 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 295.01 sec
MapReduce Total cumulative CPU time: 4 minutes 55 seconds 10 msec
Ended Job = job_1513212655323_0075
Loading data to table default.countingsimilars
Table default.countingsimilars stats: [numFiles=20, numRows=161167, totalSize=2569116, rawDataSize=2407949]
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 19  Reduce: 20   Cumulative CPU: 295.01 sec   HDFS Read: 5016299174 HDFS Write: 2570836 SUCCESS
Total MapReduce CPU Time Spent: 4 minutes 55 seconds 10 msec
OK
Time taken: 2278.495 seconds
Query ID = cloudera_20171216203737_eb118ccf-46d4-4193-902f-e0c5b2124577
Total jobs = 2
Launching Job 1 out of 2
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513212655323_0076, Tracking URL = http://quickstart.cloudera:8088/proxy/application_1513212655323_0076/
Kill Command = /usr/lib/hadoop/bin/hadoop job  -kill job_1513212655323_0076
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2017-12-16 20:37:53,016 Stage-1 map = 0%,  reduce = 0%
2017-12-16 20:38:07,540 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 3.31 sec
2017-12-16 20:38:17,044 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 5.62 sec
MapReduce Total cumulative CPU time: 5 seconds 620 msec
Ended Job = job_1513212655323_0076
Launching Job 2 out of 2
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513212655323_0077, Tracking URL = http://quickstart.cloudera:8088/proxy/application_1513212655323_0077/
Kill Command = /usr/lib/hadoop/bin/hadoop job  -kill job_1513212655323_0077
Hadoop job information for Stage-2: number of mappers: 1; number of reducers: 1
2017-12-16 20:38:44,969 Stage-2 map = 0%,  reduce = 0%
2017-12-16 20:38:53,469 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 1.08 sec
2017-12-16 20:39:01,809 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 3.02 sec
MapReduce Total cumulative CPU time: 3 seconds 20 msec
Ended Job = job_1513212655323_0077
Copying data to local directory outputQuestion2Answer2Street
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 5.62 sec   HDFS Read: 2576283 HDFS Write: 744 SUCCESS
Stage-Stage-2: Map: 1  Reduce: 1   Cumulative CPU: 3.02 sec   HDFS Read: 5390 HDFS Write: 361 SUCCESS
Total MapReduce CPU Time Spent: 8 seconds 640 msec
OK
Time taken: 146.064 seconds
-------------------------------------------------------------------------------------------------------------------------------------------------------------------
ProjectQ3 "outputQuestion3Vehicle"
Logging initialized using configuration in file:/etc/hive/conf.dist/hive-log4j.properties
OK
Time taken: 7.744 seconds
OK
Time taken: 3.789 seconds
Query ID = cloudera_20171216204545_e2a69d6c-4041-49ef-ae5f-5ce7e0ad2f4c
Total jobs = 1
Launching Job 1 out of 1
Number of reduce tasks not specified. Estimated from input data size: 20
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513212655323_0078, Tracking URL = http://quickstart.cloudera:8088/proxy/application_1513212655323_0078/
Kill Command = /usr/lib/hadoop/bin/hadoop job  -kill job_1513212655323_0078
Hadoop job information for Stage-1: number of mappers: 19; number of reducers: 20
2017-12-16 20:46:32,065 Stage-1 map = 0%,  reduce = 0%Q
2017-12-16 21:29:34,750 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 204.68 sec
MapReduce Total cumulative CPU time: 3 minutes 24 seconds 680 msec
Ended Job = job_1513212655323_0078
Loading data to table default.countingsimilars
Table default.countingsimilars stats: [numFiles=20, numRows=3344, totalSize=22413, rawDataSize=19069]
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 19  Reduce: 20   Cumulative CPU: 204.68 sec   HDFS Read: 5016300128 HDFS Write: 24056 SUCCESS
Total MapReduce CPU Time Spent: 3 minutes 24 seconds 680 msec
OK
Time taken: 2743.787 seconds
Query ID = cloudera_20171216213131_ad2c785a-8e38-410d-97e6-50c0b2249fef
Total jobs = 2
Launching Job 1 out of 2
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513212655323_0079, Tracking URL = http://quickstart.cloudera:8088/proxy/application_1513212655323_0079/
Kill Command = /usr/lib/hadoop/bin/hadoop job  -kill job_1513212655323_0079
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2017-12-16 21:32:59,028 Stage-1 map = 0%,  reduce = 0%
2017-12-16 21:33:15,913 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 1.98 sec
2017-12-16 21:33:31,507 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 3.83 sec
MapReduce Total cumulative CPU time: 3 seconds 830 msec
Ended Job = job_1513212655323_0079
Launching Job 2 out of 2
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1513212655323_0080, Tracking URL = http://quickstart.cloudera:8088/proxy/application_1513212655323_0080/
Kill Command = /usr/lib/hadoop/bin/hadoop job  -kill job_1513212655323_0080
Hadoop job information for Stage-2: number of mappers: 1; number of reducers: 1
2017-12-16 21:34:14,570 Stage-2 map = 0%,  reduce = 0%
2017-12-16 21:34:23,973 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 1.31 sec
2017-12-16 21:34:50,088 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 3.18 sec
MapReduce Total cumulative CPU time: 3 seconds 180 msec
Ended Job = job_1513212655323_0080
Copying data to local directory outputQuestion3Vehicle
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 3.83 sec   HDFS Read: 29634 HDFS Write: 604 SUCCESS
Stage-Stage-2: Map: 1  Reduce: 1   Cumulative CPU: 3.18 sec   HDFS Read: 5268 HDFS Write: 229 SUCCESS
Total MapReduce CPU Time Spent: 7 seconds 10 msec
OK
Time taken: 191.742 seconds
